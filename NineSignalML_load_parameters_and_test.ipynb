{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, vmap\n",
    "import optax\n",
    "\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import itertools\n",
    "import more_itertools as mit\n",
    "\n",
    "import os\n",
    "\n",
    "from alive_progress import alive_bar\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parallel_scan = jax.lax.associative_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_operator_diag(element_i, element_j):\n",
    "    a_i, bu_i = element_i\n",
    "    a_j, bu_j = element_j\n",
    "\n",
    "    return a_j * a_i, a_j * bu_i + bu_j\n",
    "\n",
    "\n",
    "def init_lru_parameters(N, H, r_min = 0.0, r_max = 1, max_phase = 6.28):\n",
    "    # N: state dimension, H: model dimension\n",
    "    # Initialization of Lambda is complex valued distributed uniformly on ring\n",
    "    # between r_min and r_max, with phase in [0, max_phase].\n",
    "\n",
    "    u1 = np.random.uniform(size = (N,))\n",
    "    u2 = np.random.uniform(size = (N,))\n",
    "\n",
    "    nu_log = np.log(-0.5*np.log(u1*(r_max**2-r_min**2) + r_min**2))\n",
    "    theta_log = np.log(max_phase*u2)\n",
    "\n",
    "    # Glorot initialized Input/Output projection matrices\n",
    "    B_re = np.random.normal(size=(N,H))/np.sqrt(2*H)\n",
    "    B_im = np.random.normal(size=(N,H))/np.sqrt(2*H)\n",
    "    C_re = np.random.normal(size=(H,N))/np.sqrt(N)\n",
    "    C_im = np.random.normal(size=(H,N))/np.sqrt(N)\n",
    "    D = np.random.normal(size=(H,))\n",
    "\n",
    "    # Normalization\n",
    "    diag_lambda = np.exp(-np.exp(nu_log) + 1j*np.exp(theta_log))\n",
    "    gamma_log = np.log(np.sqrt(1-np.abs(diag_lambda)**2))\n",
    "\n",
    "    return nu_log, theta_log, B_re, B_im, C_re, C_im, D, gamma_log\n",
    "\n",
    "\n",
    "def forward_LRU(lru_parameters, input_sequence):\n",
    "    # Unpack the LRU parameters\n",
    "    nu_log, theta_log, B_re, B_im, C_re, C_im, D, gamma_log = lru_parameters\n",
    "\n",
    "    # Initialize the hidden state\n",
    "    Lambda = jnp.exp(-jnp.exp(nu_log) + 1j*jnp.exp(theta_log))\n",
    "    B_norm = (B_re + 1j*B_im) * jnp.expand_dims(jnp.exp(gamma_log), axis=-1)\n",
    "    #print(B_norm.shape)\n",
    "    C = C_re + 1j*C_im\n",
    "\n",
    "    Lambda_elements = jnp.repeat(Lambda[None, ...], input_sequence.shape[0], axis=0)\n",
    "\n",
    "    Bu_elements = jax.vmap(lambda u: B_norm @ u)(input_sequence)\n",
    "    elements = (Lambda_elements, Bu_elements)\n",
    "    _, inner_states = parallel_scan(binary_operator_diag, elements) # all x_k\n",
    "    y = jax.vmap(lambda x, u: (C @ x).real + D * u)(inner_states, input_sequence)\n",
    "\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_mlp_parameters(layers):\n",
    "    # Initialize the MLP parameters\n",
    "    parameters = []\n",
    "    for i in range(len(layers)-1):\n",
    "        W = np.random.normal(size=(layers[i], layers[i+1]))/np.sqrt(layers[i])\n",
    "        b = np.zeros((layers[i+1],))\n",
    "        parameters.append((W, b))\n",
    "\n",
    "    return parameters\n",
    "\n",
    "@jit\n",
    "def forward_mlp(mlp_parameters, input, activation_function = jnp.tanh):\n",
    "    # Forward pass of the MLP\n",
    "    \n",
    "    x = input\n",
    "\n",
    "    for W, b in mlp_parameters:\n",
    "        x = x @ W + b\n",
    "        x = activation_function(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def forward_mlp_linear_with_classification(mlp_parameters, input, activation_function = jnp.tanh):\n",
    "    \n",
    "    x = input\n",
    "\n",
    "    # Only apply the MLP up to the second last layer\n",
    "    for W, b in mlp_parameters[:-1]:\n",
    "        x = x @ W + b\n",
    "        x = activation_function(x)\n",
    "\n",
    "    # Apply the last layer without activation function\n",
    "    W, b = mlp_parameters[-1]\n",
    "    x = x @ W + b\n",
    "\n",
    "    # Use the softmax function on the last layer\n",
    "    x = jax.nn.softmax(x)\n",
    "\n",
    "\n",
    "    return x\n",
    "\n",
    "def layer_normalization(activations):\n",
    "    mu  = jnp.mean(activations)\n",
    "    sigma = jnp.std(activations)\n",
    "    return (activations - mu) / sigma\n",
    "\n",
    "layer_normalization_sequence = vmap(layer_normalization)\n",
    "\n",
    "def max_pooling(sequence_to_pool):\n",
    "    return jnp.max(sequence_to_pool, axis=0)\n",
    "\n",
    "def mean_pooling(sequence_to_pool):\n",
    "    return jnp.mean(sequence_to_pool, axis=0)\n",
    "\n",
    "def sum_pooling(sequence_to_pool):\n",
    "    return jnp.sum(sequence_to_pool, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_forward(input_sequence, parameters):\n",
    "    Linear_encoder_parameter,  LRU, seconday_parameters, Linear_decoder_parameter = parameters\n",
    "\n",
    "    x = forward_mlp(Linear_encoder_parameter, input_sequence)\n",
    "    skip = x\n",
    "    x = layer_normalization_sequence(x)\n",
    "    x = forward_LRU(LRU, x)\n",
    "    x = forward_mlp(seconday_parameters, x) + skip\n",
    "    x = max_pooling(x)\n",
    "    x = forward_mlp_linear_with_classification(Linear_decoder_parameter, x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# Batch model forward\n",
    "batch_model_forward = vmap(model_forward, in_axes=(0, None))\n",
    "\n",
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "  return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "@jit\n",
    "def loss_fn(input_sequences, target_sequences, parameters):\n",
    "    y = batch_model_forward(input_sequences, parameters)\n",
    "\n",
    "    # Binary cross entropy loss\n",
    "    return -jnp.mean(jnp.sum(target_sequences * jnp.log(y), axis=1))\n",
    "\n",
    "@jit\n",
    "def model_grad(input_sequence, target_sequence, parameters):\n",
    "    return grad(loss_fn, argnums=2)(input_sequence, target_sequence, parameters)\n",
    "\n",
    "@jit\n",
    "def parameter_update(parameters, gradients, learning_rate = 0.01):\n",
    "    new_parameters = []\n",
    "    im = []\n",
    "    for parameter, gradient in zip(parameters[0], gradients[0]):\n",
    "        im.append((parameter[0] - learning_rate * gradient[0], parameter[1] - learning_rate * gradient[1]))\n",
    "\n",
    "    new_parameters.append(im)\n",
    "\n",
    "    im = []\n",
    "    for parameter, gradient in zip(parameters[1], gradients[1]):\n",
    "        im.append(parameter - learning_rate * gradient)    \n",
    "\n",
    "    new_parameters.append(im)\n",
    "\n",
    "    im = []\n",
    "    for parameter, gradient in zip(parameters[2], gradients[2]):\n",
    "        im.append((parameter[0] - learning_rate * gradient[0], parameter[1] - learning_rate * gradient[1]))\n",
    "\n",
    "    new_parameters.append(im)\n",
    "\n",
    "    im = []\n",
    "    for parameter, gradient in zip(parameters[3], gradients[3]):\n",
    "        im.append((parameter[0] - learning_rate * gradient[0], parameter[1] - learning_rate * gradient[1]))\n",
    "\n",
    "    new_parameters.append(im)\n",
    "\n",
    "    return new_parameters\n",
    "\n",
    "\n",
    "@jit\n",
    "def accuracy(input_sequences, target_sequences, parameters):\n",
    "    y = batch_model_forward(input_sequences, parameters)\n",
    "    return jnp.mean(jnp.argmax(y, axis=1) == jnp.argmax(target_sequences, axis=1))\n",
    "\n",
    "batch_model_grad = vmap(model_grad, in_axes=(0, 0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "with open('model_parameters.pkl', 'rb') as f:\n",
    "    model_parameters = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 5\n",
    "batchsize = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Array([-0.14663146, -0.51548016, -0.14853974, ..., -0.80859274,\n",
       "         -1.2138221 , -0.3857371 ], dtype=float32),\n",
       "  0,\n",
       "  1),\n",
       " (Array([ 0.0243161 ,  0.35375398, -0.360612  , ...,  1.8750998 ,\n",
       "          1.8703758 , -0.12018712], dtype=float32),\n",
       "  0,\n",
       "  2),\n",
       " (Array([ 0.7974955,  0.8332967,  1.1115386, ..., -1.5914093, -1.3005717,\n",
       "          0.7349541], dtype=float32),\n",
       "  0,\n",
       "  3),\n",
       " (Array([-0.82384086, -0.45060062, -0.93362904, ...,  0.6406777 ,\n",
       "          1.8045512 , -0.7288939 ], dtype=float32),\n",
       "  0,\n",
       "  4),\n",
       " (Array([ 1.1051197 ,  0.8783493 ,  0.86639154, ..., -1.4310888 ,\n",
       "          0.4966057 ,  1.2665831 ], dtype=float32),\n",
       "  0,\n",
       "  5),\n",
       " (Array([-0.6042226 , -0.38902044, -0.29707617, ..., -1.507831  ,\n",
       "          2.0913038 , -0.7220952 ], dtype=float32),\n",
       "  0,\n",
       "  6),\n",
       " (Array([ 0.17124599, -0.22935395, -0.05492646, ..., -1.3099109 ,\n",
       "          1.0017729 ,  0.36973727], dtype=float32),\n",
       "  0,\n",
       "  7),\n",
       " (Array([0.8356632 , 1.2018261 , 1.2292131 , ..., 1.4425874 , 0.87970614,\n",
       "         1.190423  ], dtype=float32),\n",
       "  1,\n",
       "  0),\n",
       " (Array([-0.05182349,  0.58271474,  1.1846536 , ..., -1.1918249 ,\n",
       "         -1.1259677 ,  0.35332975], dtype=float32),\n",
       "  1,\n",
       "  2),\n",
       " (Array([-0.7182585 , -0.792904  , -1.2175193 , ...,  1.2917635 ,\n",
       "          1.0417126 , -0.36430874], dtype=float32),\n",
       "  1,\n",
       "  3),\n",
       " (Array([-0.42490306, -0.0780526 ,  0.6219015 , ...,  0.13241951,\n",
       "         -1.3653115 , -0.30658507], dtype=float32),\n",
       "  1,\n",
       "  4),\n",
       " (Array([ 1.1215205 ,  1.4217528 ,  1.4512681 , ..., -0.21903336,\n",
       "         -1.0275565 ,  1.4040941 ], dtype=float32),\n",
       "  1,\n",
       "  5),\n",
       " (Array([ 0.14765984,  0.8327874 ,  0.8153689 , ...,  1.2794591 ,\n",
       "         -1.0903263 , -0.06486322], dtype=float32),\n",
       "  1,\n",
       "  6),\n",
       " (Array([ 0.9186451 ,  0.6627891 ,  0.14708504, ...,  0.2786367 ,\n",
       "         -0.65905994,  1.0085206 ], dtype=float32),\n",
       "  1,\n",
       "  7),\n",
       " (Array([ 0.3245445 , -1.1066136 , -1.7005026 , ...,  0.26953647,\n",
       "          0.1545074 ,  0.04551632], dtype=float32),\n",
       "  2,\n",
       "  0),\n",
       " (Array([-0.3179886 , -1.30984   , -1.2144578 , ...,  0.7301361 ,\n",
       "          0.11148442,  0.02010531], dtype=float32),\n",
       "  2,\n",
       "  1),\n",
       " (Array([ 0.614448  , -0.22315486, -1.4833351 , ...,  0.09000673,\n",
       "          1.5401447 ,  0.55057836], dtype=float32),\n",
       "  2,\n",
       "  3),\n",
       " (Array([-0.85937935, -1.2132238 , -1.3465685 , ...,  0.78836834,\n",
       "          1.336109  , -0.2688606 ], dtype=float32),\n",
       "  2,\n",
       "  4),\n",
       " (Array([ 1.2239535 ,  1.0906621 ,  0.40262476, ..., -0.47529772,\n",
       "         -0.83053786,  0.9674399 ], dtype=float32),\n",
       "  2,\n",
       "  5),\n",
       " (Array([-0.6162452, -1.3358338, -1.1870781, ..., -1.0044415,  1.5692219,\n",
       "         -0.8250369], dtype=float32),\n",
       "  2,\n",
       "  6),\n",
       " (Array([ 1.4307299 ,  0.96432745,  0.13960075, ...,  1.3347578 ,\n",
       "         -1.0004743 ,  1.3770614 ], dtype=float32),\n",
       "  2,\n",
       "  7),\n",
       " (Array([ 0.00573982, -1.7435019 , -1.1243675 , ..., -0.01308946,\n",
       "         -0.24473113,  0.11133142], dtype=float32),\n",
       "  3,\n",
       "  0),\n",
       " (Array([ 0.9206252 ,  1.5509516 ,  0.29366294, ..., -0.21550186,\n",
       "          0.29030445,  0.5834114 ], dtype=float32),\n",
       "  3,\n",
       "  1),\n",
       " (Array([-0.37947893, -1.3942168 , -0.6039751 , ...,  1.6480674 ,\n",
       "          0.9214798 , -0.4922789 ], dtype=float32),\n",
       "  3,\n",
       "  2),\n",
       " (Array([ 1.2376914 ,  0.3225452 , -1.1766907 , ..., -1.3679935 ,\n",
       "          0.34615186,  1.2801656 ], dtype=float32),\n",
       "  3,\n",
       "  4),\n",
       " (Array([-1.0445284 , -1.2707881 , -0.04733231, ..., -0.24904062,\n",
       "          1.5153013 , -0.7525661 ], dtype=float32),\n",
       "  3,\n",
       "  5),\n",
       " (Array([ 0.26277193, -1.1795274 , -1.3662843 , ..., -1.7162821 ,\n",
       "          0.7570219 ,  0.07652938], dtype=float32),\n",
       "  3,\n",
       "  6),\n",
       " (Array([ 1.2455151 ,  0.47453988, -0.9081376 , ...,  1.0489056 ,\n",
       "         -1.1220353 ,  1.3297975 ], dtype=float32),\n",
       "  3,\n",
       "  7),\n",
       " (Array([-0.90037453,  1.1732498 ,  0.61062783, ..., -1.1935452 ,\n",
       "         -0.6889397 , -0.6727418 ], dtype=float32),\n",
       "  4,\n",
       "  0),\n",
       " (Array([ 0.5232726 ,  1.3252378 , -0.33844522, ..., -0.61211866,\n",
       "         -0.3345941 ,  0.525192  ], dtype=float32),\n",
       "  4,\n",
       "  1),\n",
       " (Array([-1.4409142 , -0.42912835,  1.1699173 , ...,  0.1940874 ,\n",
       "         -0.65758944, -1.2022463 ], dtype=float32),\n",
       "  4,\n",
       "  2),\n",
       " (Array([ 1.0553696 , -1.1873612 , -0.78722405, ...,  0.00706906,\n",
       "          1.5359802 ,  1.1298636 ], dtype=float32),\n",
       "  4,\n",
       "  3),\n",
       " (Array([ 1.4693658 ,  0.20029823, -1.3311062 , ..., -0.7911995 ,\n",
       "         -0.6001949 ,  1.3082314 ], dtype=float32),\n",
       "  4,\n",
       "  5),\n",
       " (Array([-1.1971418 ,  0.9611561 ,  1.2623305 , ...,  1.3031551 ,\n",
       "          0.03739279, -1.0395855 ], dtype=float32),\n",
       "  4,\n",
       "  6),\n",
       " (Array([-1.0724401 ,  0.86376244,  1.2104106 , ...,  0.11422653,\n",
       "          0.72032446, -0.8531464 ], dtype=float32),\n",
       "  4,\n",
       "  7),\n",
       " (Array([ 1.2016919 , -0.9624768 , -0.15255874, ...,  0.90941656,\n",
       "          1.0229913 ,  0.905819  ], dtype=float32),\n",
       "  5,\n",
       "  0),\n",
       " (Array([-1.2646198 , -0.42058185,  1.1640252 , ..., -0.01553167,\n",
       "         -0.80470586, -1.0407295 ], dtype=float32),\n",
       "  5,\n",
       "  1),\n",
       " (Array([-1.2499853 , -0.37999353,  1.2664614 , ...,  0.9468762 ,\n",
       "         -0.54198134, -1.0710312 ], dtype=float32),\n",
       "  5,\n",
       "  2),\n",
       " (Array([-1.1719979 ,  1.1855129 ,  0.22559075, ...,  0.33670908,\n",
       "         -1.1701624 , -1.3679006 ], dtype=float32),\n",
       "  5,\n",
       "  3),\n",
       " (Array([-0.6758265, -0.6053089,  1.5717576, ...,  0.5133997,  1.1142619,\n",
       "         -0.5362448], dtype=float32),\n",
       "  5,\n",
       "  4),\n",
       " (Array([ 1.1966217 , -0.31690764, -1.3519667 , ...,  0.33034706,\n",
       "         -0.9137582 ,  1.6226931 ], dtype=float32),\n",
       "  5,\n",
       "  6),\n",
       " (Array([ 0.53125167,  1.153225  , -1.497436  , ...,  1.3330746 ,\n",
       "         -0.869416  ,  0.41025454], dtype=float32),\n",
       "  5,\n",
       "  7),\n",
       " (Array([ 0.76798743,  0.91470975, -1.4520335 , ...,  0.91065544,\n",
       "          0.782963  ,  0.5223369 ], dtype=float32),\n",
       "  6,\n",
       "  0),\n",
       " (Array([-1.455534  ,  0.6080767 ,  0.33564794, ..., -0.5583618 ,\n",
       "         -1.3089695 , -1.2057724 ], dtype=float32),\n",
       "  6,\n",
       "  1),\n",
       " (Array([-0.41328382,  0.92141443, -1.3512025 , ..., -1.1828338 ,\n",
       "         -1.2375343 , -0.43196106], dtype=float32),\n",
       "  6,\n",
       "  2),\n",
       " (Array([ 1.1128027 , -1.2883176 ,  0.74872947, ..., -0.8436745 ,\n",
       "          0.61602175,  1.4491754 ], dtype=float32),\n",
       "  6,\n",
       "  3),\n",
       " (Array([ 0.5693294 , -0.91651464,  1.2243048 , ..., -0.3620845 ,\n",
       "          1.2105724 ,  0.43869418], dtype=float32),\n",
       "  6,\n",
       "  4),\n",
       " (Array([ 0.15497428,  0.7181862 , -1.4235111 , ...,  0.76660997,\n",
       "         -1.5848494 ,  0.58308506], dtype=float32),\n",
       "  6,\n",
       "  5),\n",
       " (Array([ 0.8608089 , -1.1743846 ,  1.0586185 , ...,  0.08488521,\n",
       "         -0.74267316,  1.2559127 ], dtype=float32),\n",
       "  6,\n",
       "  7),\n",
       " (Array([-0.2854008 ,  0.658493  , -1.9653671 , ..., -0.33133578,\n",
       "         -0.08607329, -0.4270387 ], dtype=float32),\n",
       "  7,\n",
       "  0),\n",
       " (Array([ 0.9042301, -1.5077492,  1.515583 , ...,  1.26671  ,  1.1451347,\n",
       "          1.0375882], dtype=float32),\n",
       "  7,\n",
       "  1),\n",
       " (Array([-0.40488705, -0.30211648,  0.7655042 , ...,  1.254531  ,\n",
       "          0.65025604, -0.19574802], dtype=float32),\n",
       "  7,\n",
       "  2),\n",
       " (Array([-0.08212344,  0.5832428 , -0.8018378 , ..., -0.8288908 ,\n",
       "         -1.3751317 , -0.12498636], dtype=float32),\n",
       "  7,\n",
       "  3),\n",
       " (Array([-0.05443275, -0.6575183 ,  1.3943579 , ..., -0.40267786,\n",
       "          1.2938101 ,  0.15145274], dtype=float32),\n",
       "  7,\n",
       "  4),\n",
       " (Array([ 1.4087977 , -1.2690244 ,  1.3178188 , ..., -1.3493736 ,\n",
       "         -0.05686199,  1.4089464 ], dtype=float32),\n",
       "  7,\n",
       "  5),\n",
       " (Array([-0.39599478,  0.9163267 , -1.3029277 , ...,  1.8165141 ,\n",
       "         -0.7645086 , -0.08981342], dtype=float32),\n",
       "  7,\n",
       "  6),\n",
       " (Array([ 0.74652654, -0.22521733,  1.763369  , ..., -1.65713   ,\n",
       "         -1.6032088 , -1.7136825 ], dtype=float32),\n",
       "  8,\n",
       "  0),\n",
       " (Array([ 0.02458441,  0.07210653, -0.26069677, ..., -1.4405894 ,\n",
       "         -1.2936945 , -0.27325183], dtype=float32),\n",
       "  8,\n",
       "  1),\n",
       " (Array([ 0.04860217,  0.02941675, -0.2523791 , ..., -2.328242  ,\n",
       "         -1.6728674 , -0.45768726], dtype=float32),\n",
       "  8,\n",
       "  2),\n",
       " (Array([-0.3131153 , -0.12985538, -0.17748854, ..., -1.5946918 ,\n",
       "         -1.3623372 , -0.7739531 ], dtype=float32),\n",
       "  8,\n",
       "  3),\n",
       " (Array([-0.28812954,  0.29996538, -0.05244795, ...,  0.12150094,\n",
       "         -1.9016538 , -0.5029238 ], dtype=float32),\n",
       "  8,\n",
       "  4),\n",
       " (Array([-0.01937078, -0.10065255, -0.21089186, ...,  1.5593088 ,\n",
       "         -1.8729699 , -0.4107281 ], dtype=float32),\n",
       "  8,\n",
       "  5),\n",
       " (Array([-0.00602639,  0.15395077,  0.01864242, ...,  1.8551257 ,\n",
       "         -1.0535969 , -0.40353537], dtype=float32),\n",
       "  8,\n",
       "  6),\n",
       " (Array([-0.01034879, -0.09444299,  0.2498702 , ...,  0.3013911 ,\n",
       "         -0.08339041, -0.63428104], dtype=float32),\n",
       "  8,\n",
       "  7)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the test data\n",
    "with open(f\"datasets/8fmsk/waveforms_wrong_sync.pkl\", \"rb\") as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.14663146],\n",
       "       [-0.51548016],\n",
       "       [-0.14853974],\n",
       "       ...,\n",
       "       [-0.80859274],\n",
       "       [-1.2138221 ],\n",
       "       [-0.3857371 ]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqeunces = jnp.array([x[0]for x in data]).reshape(64,len(data[0][0]), 1)\n",
    "seqeunces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Untrained', 'Epoch 0', 'Epoch 1', 'Epoch 2', 'Epoch 3', 'Epoch 4', 'Accuracy'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parameters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Epoch 719'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m64\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(model_forward(seqeunces[i], \u001b[43mmodel_parameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch 719\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[0;32m      9\u001b[0m results\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Epoch 719'"
     ]
    }
   ],
   "source": [
    "#  Test the model with non-synced data\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(64):\n",
    "    results.append(model_forward(seqeunces[i], model_parameters[\"Epoch 719\"]))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(np.array(results).T, cmap='viridis')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
