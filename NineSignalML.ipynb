{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jit, grad, vmap\n",
    "import optax\n",
    "\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import itertools\n",
    "import more_itertools as mit\n",
    "\n",
    "import os\n",
    "\n",
    "from alive_progress import alive_bar\n",
    "import gc\n",
    "\n",
    "parallel_scan = jax.lax.associative_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_operator_diag(element_i, element_j):\n",
    "    a_i, bu_i = element_i\n",
    "    a_j, bu_j = element_j\n",
    "\n",
    "    return a_j * a_i, a_j * bu_i + bu_j\n",
    "\n",
    "\n",
    "def init_lru_parameters(N, H, r_min = 0.0, r_max = 1, max_phase = 6.28):\n",
    "    # N: state dimension, H: model dimension\n",
    "    # Initialization of Lambda is complex valued distributed uniformly on ring\n",
    "    # between r_min and r_max, with phase in [0, max_phase].\n",
    "\n",
    "    u1 = np.random.uniform(size = (N,))\n",
    "    u2 = np.random.uniform(size = (N,))\n",
    "\n",
    "    nu_log = np.log(-0.5*np.log(u1*(r_max**2-r_min**2) + r_min**2))\n",
    "    theta_log = np.log(max_phase*u2)\n",
    "\n",
    "    # Glorot initialized Input/Output projection matrices\n",
    "    B_re = np.random.normal(size=(N,H))/np.sqrt(2*H)\n",
    "    B_im = np.random.normal(size=(N,H))/np.sqrt(2*H)\n",
    "    C_re = np.random.normal(size=(H,N))/np.sqrt(N)\n",
    "    C_im = np.random.normal(size=(H,N))/np.sqrt(N)\n",
    "    D = np.random.normal(size=(H,))\n",
    "\n",
    "    # Normalization\n",
    "    diag_lambda = np.exp(-np.exp(nu_log) + 1j*np.exp(theta_log))\n",
    "    gamma_log = np.log(np.sqrt(1-np.abs(diag_lambda)**2))\n",
    "\n",
    "    return nu_log, theta_log, B_re, B_im, C_re, C_im, D, gamma_log\n",
    "\n",
    "\n",
    "def forward_LRU(lru_parameters, input_sequence):\n",
    "    # Unpack the LRU parameters\n",
    "    nu_log, theta_log, B_re, B_im, C_re, C_im, D, gamma_log = lru_parameters\n",
    "\n",
    "    # Initialize the hidden state\n",
    "    Lambda = jnp.exp(-jnp.exp(nu_log) + 1j*jnp.exp(theta_log))\n",
    "    B_norm = (B_re + 1j*B_im) * jnp.expand_dims(jnp.exp(gamma_log), axis=-1)\n",
    "    #print(B_norm.shape)\n",
    "    C = C_re + 1j*C_im\n",
    "\n",
    "    Lambda_elements = jnp.repeat(Lambda[None, ...], input_sequence.shape[0], axis=0)\n",
    "\n",
    "    Bu_elements = jax.vmap(lambda u: B_norm @ u)(input_sequence)\n",
    "    elements = (Lambda_elements, Bu_elements)\n",
    "    _, inner_states = parallel_scan(binary_operator_diag, elements) # all x_k\n",
    "    y = jax.vmap(lambda x, u: (C @ x).real + D * u)(inner_states, input_sequence)\n",
    "\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_mlp_parameters(layers):\n",
    "    # Initialize the MLP parameters\n",
    "    parameters = []\n",
    "    for i in range(len(layers)-1):\n",
    "        W = np.random.normal(size=(layers[i], layers[i+1]))/np.sqrt(layers[i])\n",
    "        b = np.zeros((layers[i+1],))\n",
    "        parameters.append((W, b))\n",
    "\n",
    "    return parameters\n",
    "\n",
    "@jit\n",
    "def forward_mlp(mlp_parameters, input, activation_function = jnp.tanh):\n",
    "    # Forward pass of the MLP\n",
    "    \n",
    "    x = input\n",
    "\n",
    "    for W, b in mlp_parameters:\n",
    "        x = x @ W + b\n",
    "        x = activation_function(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def forward_mlp_linear_with_classification(mlp_parameters, input, activation_function = jnp.tanh):\n",
    "    \n",
    "    x = input\n",
    "\n",
    "    # Only apply the MLP up to the second last layer\n",
    "    for W, b in mlp_parameters[:-1]:\n",
    "        x = x @ W + b\n",
    "        x = activation_function(x)\n",
    "\n",
    "    # Apply the last layer without activation function\n",
    "    W, b = mlp_parameters[-1]\n",
    "    x = x @ W + b\n",
    "\n",
    "    # Use the softmax function on the last layer\n",
    "    x = jax.nn.softmax(x)\n",
    "\n",
    "\n",
    "    return x\n",
    "\n",
    "def layer_normalization(activations):\n",
    "    mu  = jnp.mean(activations)\n",
    "    sigma = jnp.std(activations)\n",
    "    return (activations - mu) / sigma\n",
    "\n",
    "layer_normalization_sequence = vmap(layer_normalization)\n",
    "\n",
    "def max_pooling(sequence_to_pool):\n",
    "    return jnp.max(sequence_to_pool, axis=0)\n",
    "\n",
    "def mean_pooling(sequence_to_pool):\n",
    "    return jnp.mean(sequence_to_pool, axis=0)\n",
    "\n",
    "def sum_pooling(sequence_to_pool):\n",
    "    return jnp.sum(sequence_to_pool, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "Linear_encoder_parameter  = init_mlp_parameters([1,5,10])\n",
    "seconday_parameters = init_mlp_parameters([10,10,10])\n",
    "LRU = init_lru_parameters(10, 10, r_min =0.9, r_max=0.999)\n",
    "Linear_decoder_parameter = init_mlp_parameters([10,10,9])\n",
    "\n",
    "model_parameters = [Linear_encoder_parameter, LRU, seconday_parameters, Linear_decoder_parameter]\n",
    "\n",
    "def model_forward(input_sequence, parameters):\n",
    "    Linear_encoder_parameter,  LRU, seconday_parameters, Linear_decoder_parameter = parameters\n",
    "\n",
    "    x = forward_mlp(Linear_encoder_parameter, input_sequence)\n",
    "    skip = x\n",
    "    x = layer_normalization_sequence(x)\n",
    "    x = forward_LRU(LRU, x)\n",
    "    x = forward_mlp(seconday_parameters, x) + skip\n",
    "    x = max_pooling(x)\n",
    "    x = forward_mlp_linear_with_classification(Linear_decoder_parameter, x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# Batch model forward\n",
    "batch_model_forward = vmap(model_forward, in_axes=(0, None))\n",
    "\n",
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "  return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "@jit\n",
    "def loss_fn(input_sequences, target_sequences, parameters):\n",
    "    y = batch_model_forward(input_sequences, parameters)\n",
    "\n",
    "    # Binary cross entropy loss\n",
    "    return -jnp.mean(jnp.sum(target_sequences * jnp.log(y), axis=1))\n",
    "\n",
    "@jit\n",
    "def model_grad(input_sequence, target_sequence, parameters):\n",
    "    return grad(loss_fn, argnums=2)(input_sequence, target_sequence, parameters)\n",
    "\n",
    "@jit\n",
    "def parameter_update(parameters, gradients, learning_rate = 0.01):\n",
    "    new_parameters = []\n",
    "    im = []\n",
    "    for parameter, gradient in zip(parameters[0], gradients[0]):\n",
    "        im.append((parameter[0] - learning_rate * gradient[0], parameter[1] - learning_rate * gradient[1]))\n",
    "\n",
    "    new_parameters.append(im)\n",
    "\n",
    "    im = []\n",
    "    for parameter, gradient in zip(parameters[1], gradients[1]):\n",
    "        im.append(parameter - learning_rate * gradient)    \n",
    "\n",
    "    new_parameters.append(im)\n",
    "\n",
    "    im = []\n",
    "    for parameter, gradient in zip(parameters[2], gradients[2]):\n",
    "        im.append((parameter[0] - learning_rate * gradient[0], parameter[1] - learning_rate * gradient[1]))\n",
    "\n",
    "    new_parameters.append(im)\n",
    "\n",
    "    im = []\n",
    "    for parameter, gradient in zip(parameters[3], gradients[3]):\n",
    "        im.append((parameter[0] - learning_rate * gradient[0], parameter[1] - learning_rate * gradient[1]))\n",
    "\n",
    "    new_parameters.append(im)\n",
    "\n",
    "    return new_parameters\n",
    "\n",
    "\n",
    "@jit\n",
    "def accuracy(input_sequences, target_sequences, parameters):\n",
    "    y = batch_model_forward(input_sequences, parameters)\n",
    "    return jnp.mean(jnp.argmax(y, axis=1) == jnp.argmax(target_sequences, axis=1))\n",
    "\n",
    "batch_model_grad = vmap(model_grad, in_axes=(0, 0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 5\n",
    "batchsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "with open(f\"datasets\\8fmsk\\waveforms_CNO.pkl\", \"rb\") as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "# Randomize the dataset\n",
    "perm = np.random.permutation(len(data))\n",
    "\n",
    "shuffled_data = [data[i] for i in perm]\n",
    "\n",
    "# Seperate into a train set and test set\n",
    "del data\n",
    "\n",
    "train_sequences = jnp.array([x[0] for x in shuffled_data[:int(0.8*len(shuffled_data))]]).reshape((int(0.8*len(shuffled_data)),20000,1)).reshape((int(0.8*len(shuffled_data)/batchsize),batchsize,-1,1))\n",
    "test_sequences = jnp.array([x[0] for x in shuffled_data[int(0.8*len(shuffled_data)):]]).reshape((len(shuffled_data) - int(0.8*len(shuffled_data)),20000,1)).reshape((int((len(shuffled_data) - int(0.8*len(shuffled_data)))/batchsize),batchsize,-1,1))\n",
    "\n",
    "train_labels = one_hot(jnp.array([x[1] for x in shuffled_data[:int(0.8*len(shuffled_data))]]), 9).reshape((int(0.8*len(shuffled_data)/batchsize),batchsize,-1))\n",
    "test_labels = one_hot(jnp.array([x[1] for x in shuffled_data[int(0.8*len(shuffled_data)):]]), 9).reshape((int((len(shuffled_data) - int(0.8*len(shuffled_data)))/batchsize),batchsize,-1))\n",
    "\n",
    "del shuffled_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = jax.device_put(model_parameters, jax.devices()[0])\n",
    "train_sequences = jax.device_put(train_sequences, jax.devices()[0])\n",
    "train_labels = jax.device_put(train_labels, jax.devices()[0])\n",
    "test_sequences = jax.device_put(test_sequences, jax.devices()[0])\n",
    "test_labels = jax.device_put(test_labels, jax.devices()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "on 0: C:\\Users\\David.Johansen\\AppData\\Roaming\\Python\\Python310\\site-packages\\jax\\_src\\lax\\lax.py:3227: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "        x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|⚠︎                                       | (!) 0/720 [0%] in 10.1s (0.00/s) \n"
     ]
    }
   ],
   "source": [
    "optimizer = optax.adam(1e-3)\n",
    "opt_state = optimizer.init(model_parameters)\n",
    "\n",
    "train_acc = []\n",
    "test_acc   = []\n",
    "\n",
    "model_parameters_list = {\"Untrained\": model_parameters}\n",
    "\n",
    "for k in range(epochs):\n",
    "    with alive_bar(len(train_sequences)) as bar:\n",
    "        for i in range(len(train_sequences)):\n",
    "            grads = model_grad(train_sequences[i], train_labels[i], model_parameters)\n",
    "            updates, opt_state = optimizer.update(grads, opt_state)\n",
    "            model_parameters = optax.apply_updates(model_parameters, updates)\n",
    "            bar()\n",
    "    print(f\"Epoch {k+1} completed\")\n",
    "    print(\"Calculating accuracy\")\n",
    "    train_acc.append(np.mean([accuracy(jnp.array(x), jnp.array(y), model_parameters) for x, y in zip(train_sequences, train_labels)]))\n",
    "    test_acc.append(np.mean([accuracy(jnp.array(x), jnp.array(y), model_parameters) for x, y in zip(test_sequences, test_labels)]))\n",
    "\n",
    "    print(f\"Train Accuracy: {train_acc[k]}\")\n",
    "    print(f\"Test Accuracy: {test_acc[k]}\")\n",
    "\n",
    "    model_parameters_list[f\"Epoch {k}\"] = model_parameters\n",
    "\n",
    "model_parameters_list[\"Accuracy\"] = (train_acc, test_acc)\n",
    "\n",
    "with open(\"model_parameters_8MFSK_with_CNO.pkl\", \"wb\") as f:\n",
    "    pkl.dump(model_parameters_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|████████████████████████████████████████| 360/360 [100%] in 4:17.0 (1.40/s) \n",
      "Calculating accuracy\n",
      "Train Accuracy: 0.8913888931274414\n",
      "Test Accuracy: 0.8788888454437256\n",
      "Epoch 1\n",
      "|█████▎⚠︎                                 | (!) 47/360 [13%] in 26.5s (1.77/s) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m alive_bar(train_labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m bar:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m xs, ys \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(train_sequences, train_labels):\n\u001b[1;32m---> 12\u001b[0m         gradients \u001b[38;5;241m=\u001b[39m model_grad(xs, \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mys\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, model_parameters)\n\u001b[0;32m     13\u001b[0m         model_parameters \u001b[38;5;241m=\u001b[39m parameter_update(model_parameters, gradients)\n\u001b[0;32m     14\u001b[0m         bar()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:5016\u001b[0m, in \u001b[0;36marray\u001b[1;34m(object, dtype, copy, order, ndmin, device)\u001b[0m\n\u001b[0;32m   5014\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m   5015\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m-> 5016\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43melt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5017\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5018\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:4108\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out, dtype)\u001b[0m\n\u001b[0;32m   4106\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape(a) \u001b[38;5;241m!=\u001b[39m shape0:\n\u001b[0;32m   4107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll input arrays must have the same shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 4108\u001b[0m   new_arrays\u001b[38;5;241m.\u001b[39mappend(\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   4109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concatenate(new_arrays, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:2196\u001b[0m, in \u001b[0;36mexpand_dims\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m   2194\u001b[0m util\u001b[38;5;241m.\u001b[39mcheck_arraylike(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m, a)\n\u001b[0;32m   2195\u001b[0m axis \u001b[38;5;241m=\u001b[39m _ensure_index_tuple(axis)\n\u001b[1;32m-> 2196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\jax\\_src\\lax\\lax.py:1689\u001b[0m, in \u001b[0;36mexpand_dims\u001b[1;34m(array, dimensions)\u001b[0m\n\u001b[0;32m   1687\u001b[0m   result_shape\u001b[38;5;241m.\u001b[39minsert(i, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1688\u001b[0m broadcast_dims \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim_out) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dims_set]\n\u001b[1;32m-> 1689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbroadcast_in_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbroadcast_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\jax\\_src\\lax\\lax.py:1086\u001b[0m, in \u001b[0;36mbroadcast_in_dim\u001b[1;34m(operand, shape, broadcast_dimensions)\u001b[0m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1085\u001b[0m   dyn_shape, static_shape \u001b[38;5;241m=\u001b[39m [], shape  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m-> 1086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbroadcast_in_dim_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyn_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstatic_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbroadcast_dimensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbroadcast_dimensions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\jax\\_src\\core.py:438\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[1;34m(self, *args, **params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m    436\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39menable_checks\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    437\u001b[0m           \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mor\u001b[39;00m valid_jaxtype(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)), args\n\u001b[1;32m--> 438\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_top_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\jax\\_src\\core.py:442\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[1;34m(self, trace, args, params)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m    441\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m pop_level(trace\u001b[38;5;241m.\u001b[39mlevel):\n\u001b[1;32m--> 442\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\jax\\_src\\core.py:948\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[1;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m call_impl_with_key_reuse_checks(primitive, primitive\u001b[38;5;241m.\u001b[39mimpl, \u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 948\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mimpl(\u001b[38;5;241m*\u001b[39mtracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\jax\\_src\\dispatch.py:90\u001b[0m, in \u001b[0;36mapply_primitive\u001b[1;34m(prim, *args, **params)\u001b[0m\n\u001b[0;32m     88\u001b[0m prev \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m   outs \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m   lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(prev)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_acc = []\n",
    "# test_acc = []\n",
    "\n",
    "# model_parameters_list = {\"Untrained\": model_parameters}\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(epochs):\n",
    "#     print(f\"Epoch {i}\")\n",
    "#     with alive_bar(train_labels.shape[0]) as bar:\n",
    "#         for xs, ys in zip(train_sequences, train_labels):\n",
    "#             gradients = model_grad(xs, jnp.array([ys]), model_parameters)\n",
    "#             model_parameters = parameter_update(model_parameters, gradients)\n",
    "#             bar()\n",
    "#     print(\"Calculating accuracy\")\n",
    "#     train_acc.append(np.mean([accuracy(jnp.array(x), jnp.array(y), model_parameters) for x, y in zip(train_sequences, train_labels)]))\n",
    "#     test_acc.append(np.mean([accuracy(jnp.array(x), jnp.array(y), model_parameters) for x, y in zip(test_sequences, test_labels)]))\n",
    "\n",
    "#     print(f\"Train Accuracy: {train_acc[i]}\")\n",
    "#     print(f\"Test Accuracy: {test_acc[i]}\")\n",
    "\n",
    "#     model_parameters_list[f\"Epoch {i}\"] = model_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Untrained', 'Epoch 0'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_parameters_list.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_acc, label=\"Train\")\t\n",
    "plt.plot(test_acc, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy [%]\")\n",
    "plt.savefig(\"accuracy.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving the model\n",
    "# with open(\"model.pkl\", \"wb\") as f:\n",
    "#     pkl.dump(model_parameters_list, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
